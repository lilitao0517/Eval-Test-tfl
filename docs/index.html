<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&family=Tenor+Sans&display=swap" rel="stylesheet">
    <script src="https://kit.fontawesome.com/7c463d890f.js" crossorigin="anonymous"></script>

       <!-- Your other head content here -->
    <!-- <script>
     function showJsonPopup(event) {
    event.preventDefault(); // Prevent default link behavior
    // Fetch JSON data
    fetch('./table_data.json')
        .then(response => response.json())
        .then(data => {
            // Construct JSON content string
            let content = '<ul>';
            for (const [key, value] of Object.entries(data)) {
                content += <li><strong>${key}:</strong> ${JSON.stringify(value)}</li>;
            }
            content += '</ul>';
            // Create popup window
            const popupWindow = window.open('', '_blank', 'width=600,height=400,scrollbars=yes,resizable=yes');
            popupWindow.document.write(<html><head><title>JSON Data</title></head><body>${content}</body></html>);
        })
        .catch(error => console.error('Error loading JSON:', error));
}
  </script> -->


    <title>STING-BEE</title>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-KT5YTF7856"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-KT5YTF7856');
    </script>  
    <link rel="icon" type="image/x-icon" href="img/quilt1m.png">

    <style>
        .quilt{
        
        font-variant: small-caps;
        font-family: 'Latin Modern Roman', serif;
    
        }
        .div1{
            background-color:#9ad9ec; 
            border-radius: 15px;
        }

        .div2{
          display: block;
          padding: 9.5px;
          margin: 0 0 10px;
          font-size: 14px;
          line-height: 1.42857143;
          word-break: break-all;
          word-wrap: break-word;
          color: #333;
          background-color: #f5f5f5;
          border: 1px solid #ccc;
          border-radius: 4px;
        }
        .div-contributions {
          background-color: #f7f7f7; /* Light Grey */
          border-radius: 15px;
          padding: 20px;
        } 

        .divtext1{
            font-size: 40px;
        }

        .font1{
            font-family: 'Tenor Sans', sans-serif;
        }

        .font2{
            font-family: 'Roboto', sans-serif;
        }

        .font3 {
        font-family: 'Roboto', sans-serif; /* Clean font for subheadings and text */
        font-weight: 400; /* Normal weight for readability */
        }

        .btndes{
          border-radius: 20px;
          background-color: #363636;
          color: white;
          text-decoration: none !important;
        }

        .btndes:hover {
          background-color:black;
          color: white;
        }

        .navsize1{
            font-size: 25px;
        }
        .navsize{
            font-size: 18px;;
        }
        .absfont{
            font-size: 17px;;
        }

        .navcolor{
            background-color: #f7f7f7;
            border: none; /* Remove border */
        }

        .navfontc {
            color: black !important; /* Set font color to black */
        }

        .margin-left{
            margin-left: 10px;
        }

        .size2{
            font-size: 23px;
        }

        .datalink{
            background-color:#E2E0E4;
            border-radius: 10px;

        }

        .margin{
            margin-left: 10px;
            font-size: 15px;
        }

        .card {
            box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.16), 0 2px 10px 0 rgba(0, 0, 0, 0.12);
        }

        .card {
          margin-top: 10px;
          box-sizing: border-box;
          border-radius: 2px;
          background-clip: padding-box;
          min-height:200px;
        }

        .card span.card-title {
          color: #fff;
          font-size: 24px;
          font-weight: 300;
          text-transform: uppercase;
        }

        .card .card-image {
          position: relative;
          overflow: hidden;
        }

        .card .card-image img {
          border-radius: 2px 2px 0 0;
          background-clip: padding-box;
          position: relative;
          z-index: -1;
        }

        .card .card-image span.card-title {
          position: absolute;
          bottom: 0;
          left: 0;
          padding: 16px;
        }

        .card .card-content {
          padding: 10px;
          border-radius: 0 0 2px 2px;
          background-clip: padding-box;
          box-sizing: border-box;
        }

        .card .card-content p {
          margin: 0;
          color: inherit;
        }

        .card .card-content span.card-title {
          line-height: 48px;
        }

        .card .card-action {
          border-top: 1px solid rgba(160, 160, 160, 0.2);
          padding: 16px;
        }

        .card .card-action a {
          color: #ffab40;
          margin-right: 16px;
          transition: color 0.3s ease;
          text-transform: uppercase;
        }

        .card .card-action a:hover {
          color: #ffd8a6;
          text-decoration: none;
        }
        img:hover {
          transform: scale(1.02);
          transition: all 0.3s ease-in-out;
        }
        .navcolor {
          background-color: #f7f7f7;; /* Light Grey background color */
          border: none; /* Remove border */
        }

        .navfontc {
          color: black !important; /* Set font color to black */
          font-weight: bold;
        }

        .navfontc:hover {
          color: #082888 !important; /* Light red on hover */
        }
        /* Ensure dropdown menu background is consistent */
        .dropdown-menu {
          background-color: #f7f7f7 !important; /* Light grey background */
          border: none; /* Remove border */
        }

        /* Style dropdown menu items */
        .dropdown-menu > li > a {
          color: black !important; /* Set text color to black */
          font-weight: bold; /* Make text bold */
          background-color: transparent !important; /* Transparent background */
        }

        /* Hover effect for dropdown menu items */
        .dropdown-menu > li > a:hover {
          background-color: #e0e0e0 !important; /* Light grey on hover */
          color: #082888 !important; /* Optional: Change text color on hover */
        }
        /* Ensure the dropdown toggle retains its styling */
        .dropdown-toggle.navfontc {
          background-color: transparent !important; /* Keep the background transparent */
          color: black !important; /* Ensure the text color remains black */
          font-weight: bold; /* Keep the text bold */
          border: none; /* Remove any border */
        }

/* Hover and active state for the dropdown toggle */
.dropdown-toggle.navfontc:hover,
.dropdown-toggle.navfontc:focus {
    background-color: #e0e0e0 !important; /* Light grey on hover or focus */
    color: #082888 !important; /* Optional: Change text color on hover or focus */
}


    </style>
  </head>
  <body>
  <nav class="navbar navbar-inverse navbar-fixed-top navcolor">
    <div class="container-fluid">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>                        
        </button>
        <a class="navbar-brand font1 navsize1 navfontc" href="https://divs1159.github.io/STING-BEE"><span class="quilt">STING-BEE</span></a> 
        
      </div>
      <div class="collapse navbar-collapse" id="myNavbar">
        <ul class="nav navbar-nav navsize">
          <!-- <li><a href="https://arxiv.org/abs/2504.02823">Paper</a></li> -->
          <!-- <li><a href="#dataset">Dictionary</a></li> -->
          <li class="dropdown">
            <a href="#" class="dropdown-toggle navfontc" data-toggle="dropdown">Contributions <span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li><a href="#stcray" class="navfontc">STCray Dataset</a></li>
              <li><a href="#sting-protocol" class="navfontc">STING Protocol</a></li>
              <li><a href="#stingbee" class="navfontc">STING-BEE Train/Eval</a></li>
            </ul> 
          </li> 
          <li><a href="https://youtu.be/_efmQW2nSGw" target="_blank" class="navfontc">Video</a></li> 
          <li><a href="#result" class="navfontc">Results</a></li>
          <!-- <li><a href="#author">Authors</a></li> -->
          <li><a href="#cite" class="navfontc">Citation</a></li>
          <li><a href="#contact" class="navfontc">Contact</a></li>
          <!-- Dropdown for Contributions -->
          
        </ul>
      </div>
    </div>
  </nav>
    <div class="container div1" align="center"> 
      <div class="text-center">
        <a href="javascript:void(0);" onclick="openModal('logoModal', 'logoModalImg', this)">
          <img class="img-fluid" src="./images/logo.jpeg" alt="STING-BEE Logo" style="max-width: 150px; margin-top: 50px; margin-bottom: 10px;">
        </a>
      </div>
      
      <!-- Modal for Logo -->
      <div id="logoModal" class="modal">
        <span class="close" onclick="closeModal('logoModal')">&times;</span>
        <img class="modal-content" id="logoModalImg">
      </div> 
      <h1 class="divtext1 font1">
        <b><span class="quilt">STING-BEE</span>: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection 
        &emsp; <span class="cvpr-text">[CVPR 2025]</span></b> </h1>
      <br>
      
      <h4 class="font3">
        <a href="https://www.linkedin.com/in/divya-velayudhan-958052175" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Divya Velayudhan</b></a>, 
        <a href="https://scholar.google.com/citations?user=2tHwtZwAAAAJ&hl=en" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Abdelfatah Ahmed</b></a>, 
        <a href="https://www.linkedin.com/in/mohamad-alansari/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;""><b>Mohamad Alansari</b></a>, 
        <a href="https://www.linkedin.com/in/neha-gour-3b501055/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Neha Gour</b></a>, 
        <a href="https://www.linkedin.com/in/abderaouf-behouch-2a1207102/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Abderaouf Behouch</b></a>, 
        <a href="https://www.linkedin.com/in/taimur-hassan-46a4a950/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Taimur Hassan</b></a>, 
        <a href="https://www.linkedin.com/in/wasimsyedtalal/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Syed Talal Wasim</b></a>, 
        <a href="https://scholar.google.com/citations?user=Y0KW_J4AAAAJ&hl=en" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Nabil Maalej</b></a>, 
        <a href="https://muzammal-naseer.com/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Muzammal Naseer</b></a>, 
        <a href="https://www.linkedin.com/in/juergen-gall-a78103204/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Juergen Gall</b></a>, 
        <a href="https://www.linkedin.com/in/mohammed-bennamoun-b3147174/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Mohammed Bennamoun</b></a>, 
        <a href="https://www.linkedin.com/in/ernestodamiani/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Ernesto Damiani</b></a>, 
        <a href="https://www.linkedin.com/in/naoufel-werghi-80846338/" target="_blank" style="color: rgb(22, 22, 175); text-decoration: underline;"><b>Naoufel Werghi</b></a>
    </h4>

<p align="center" style="font-size: 18px;">
  Khalifa University of Science and Technology &nbsp;&nbsp;&nbsp;&nbsp; Abu Dhabi University <br>
  University of Bonn &nbsp;&nbsp;&nbsp;&nbsp; Lamarr Institute for ML and AI &nbsp;&nbsp;&nbsp;&nbsp; The University of Western Australia
</p>
      <a class="btn navsize margin-left btndes" href="https://github.com/Divs1159/STING-BEE" role="button">
   Code <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 496 512">
   <style>svg{fill:#fdfcfc}</style>
   <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8z"/>
   </svg>
</a>

<!-- Dataset Button -->
<a class="btn navsize margin-left btndes" href="https://huggingface.co/datasets/Naoufel555/STCray-Dataset" role="button">
   Dataset <i class="fas fa-database"></i>
</a>

<!-- arXiv Button -->
<a class="btn navsize margin-left btndes" href="https://arxiv.org/abs/2504.02823" role="button">
   arXiv <i class="fas fa-file-alt"></i>
</a>

      <br><br>
  </div>
  <br><br>
  <div class="container">
       <br>
      <p class="absfont">
        STING-BEE is the first domain-aware visual AI assistant for X-ray baggage security screening, trained using our STCray dataset, the first multimodal X-ray baggage security dataset with 46,642 image-caption paired scans spanning 21 categories, including novel threat categories such as
        Improvised Explosive Devices (IEDs) and 3D-printed firearms. STING-BEE provides a unified platform for scene comprehension, referring threat localization, visual grounding, and VQA, establishing new baselines for X-ray baggage security research. 
      </p>
  </div>
  <br><br>

    <!-- Contributions Section -->
<div class="container div-contributions">
    <h1>üèÜ Contributions</h1> <br> 
    <p class="absfont">
        <b><a href="#stcray" style="color:#007bff;">STCray Dataset</a></b> - The first multimodal X-ray security dataset with <b>46,642 image-caption pairs</b>.
        <br>
        <b><a href="#sting-protocol" style="color:#007bff;">STING Protocol</a></b> - A structured approach ensuring realistic threat concealment by systematically varying threat placement and occlusion.
        <br>
        <b><a href="#stingbee" style="color:#007bff;">STING-BEE</a></b> - The first domain-aware VLM for X-ray baggage security screening.
        <br>
        It establishes new baselines for multimodal learning in X-ray baggage security.
    </p>
</div>
<br><br>
<div class="text-center">
  <iframe 
    width="45%" 
    height="580" 
    src="https://www.youtube.com/embed/_efmQW2nSGw?start=0" 
    title="YouTube video player" 
    frameborder="0" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
    allowfullscreen>
  </iframe>
</div>
<hr style="border: 0; height: 1px; background: #d3d3d3; margin: 30px 0;">  
<br><br>
 

    <!-- STCray Dataset Section -->
<div class="container" id="stcray">
  <h1>üìå STCray Dataset</h1> <br> 
  <p class="absfont text-justify">
    <b>STCray</b> is the first <b>multimodal X-ray baggage security dataset</b>, featuring <b>46,642 image-caption paired scans</b> spanning <b>21 threat categories</b>.
     It includes real-world threat concealment scenarios, ensuring diverse and representative data for X-ray security AI research.
  </p>
  <div class="row">
      <!-- Left Column: Image -->
<div class="col-md-6 text-center">
  <a href="javascript:void(0);" onclick="openModal('topFig1Modal', 'topFig1Img', this)">
    <img class="img-fluid img-responsive" src="./images/TopFig1.png" style="max-width: 100%;" alt="STCray Characteristics">
  </a>
</div>

<!-- Modal for TopFig1 -->
<div id="topFig1Modal" class="modal">
  <span class="close" onclick="closeModal('topFig1Modal')">&times;</span>
  <img class="modal-content" id="topFig1Img">
</div>

      <!-- Right Column: Text -->
      <div class="col-md-6">
          <p class="absfont text-justify">
              The dataset features a wide spectrum of threat categories, ranging from sharp metallic threats to flammable materials, including <i>Explosive</i>, <i>Gun</i>, <i>3D-printed Gun</i>, <i>Knife</i>, <i>Cutter</i>, <i>Blade</i>, <i>Shaving Razor</i>, <i>Lighter</i>, <i>Syringe</i>, <i>Battery</i>,
              <i>Nail Cutter</i>, <i>Other Sharp Item</i>, <i>Powerbank</i>, <i>Scissors</i>, <i>Hammer</i>, <i>Pliers</i>, <i>Wrench</i>, <i>Screwdriver</i>, <i>Handcuffs</i>, and <i>Bullet</i>. Unlike existing datasets that fail to capture real-world threats adequately,
              STCray emphasizes sophisticated prohibited items, such as <b>IEDs</b> and <b>3D-printed firearms</b>, alongside <b>realistic concealment scenarios</b> that mimic smuggling tactics.
          </p>
      </div>
  </div>
  <br><br>
 
  <!-- Statistical Distribution Section -->
<div class="row">
  
  <h3><u>Statistical Distribution</u></h3> <br>
  <p class="absfont text-justify">
    <b>STCray dataset</b> is comprehensively annotated, featuring 46,642 samples with detailed descriptions, bounding boxes, and pixel-level labels. 
    The dataset comprises 30,044 training and 16,598 test images. It includes <b>57,218 threat instances across 20 threat categories</b>.
  </p>

  <div class="col-md-6 text-center">
      <figure>
          <img class="img-fluid" src="./images/Data_distfinal.png" style="max-width: 85%; border-radius: 8px; box-shadow: 0px 2px 8px rgba(0,0,0,0.1);" alt="STCray Data Distribution">
          <figcaption class="absfont"><i>Instance-wise threat distribution in STCray.</i></figcaption>
      </figure>
  </div>

  <div class="col-md-6 text-center">
      <figure>
          <img class="img-fluid" src="./images/Table_dist.png" style="max-width: 50%; border-radius: 8px; box-shadow: 0px 2px 8px rgba(0,0,0,0.1);" alt="STCray Train-Test Table summary">
          <figcaption class="absfont"><i>Train-Test summary in STCray dataset.</i></figcaption>
      </figure>
  </div>

  <p class="absfont text-justify">
    Figure shows instance-wise distribution of threat categories in the STCray dataset. Left: Radial plot depicting overall counts; 
    Right: Table summary across train and test sets. STCray contains 36,438 single-threat images and 9,255 scans with multiple threats.
  </p>
</div>
    <br><br>

  <hr style="border: 0; height: 1px; background: #d3d3d3; margin: 30px 0;">    

  <!-- STING Protocol Section -->
<div class="container" id="sting-protocol">
  <h1>üìå STING Protocol</h1> <br> 

  <p class="absfont text-justify">
    <b>STING (Strategic Threat Concealing) Protocol</b> is a structured approach designed to systematically vary the position, orientation, and concealment of threat objects in X-ray baggage scans. 
    This protocol ensures a **diverse and realistic dataset**, simulating real-world smuggling tactics used in aviation security.
  </p>

  <div class="row">
      <!-- Left Column: Image -->
      <!-- STING Protocol Image (Left Column) -->
<div class="col-md-6 text-center">
  <a href="./images/DataColl_4.png" target="_blank">
      <img class="img-fluid img-responsive" src="./images/DataColl_4.png" style="max-width: 100%;" alt="STING Protocol Illustration">
  </a>
</div>

<!-- Modal for STING Protocol Image -->
<div id="stingModal" class="modal">
  <span class="close" onclick="closeModal('stingModal')">&times;</span>
  <img class="modal-content" id="stingModalImg">
</div>

      <!-- Right Column: Text -->
      <div class="col-md-6 d-flex align-items-center justify-content-center h-100">
        <div class="text-wrapper">
            <p class="absfont text-justify">
              <br></br><br></br><br></br>

                The STING protocol underpins the STCray dataset, categorizing clutter into four levels‚ÄîLimited, Medium, Heavy, and 
                Extreme‚Äîprogressively increasing occlusions and distractions. Concealment sublevels further diversify scenarios, ranging from 
                low-density (e.g., organic items like books) to extreme configurations such as metallic grids and multi-layered superimposed materials. 
                These concealments are further diversified by systematically varying the position and orientation of the threat, distorting threat appearances.
            </p>
        </div>
    </div>
  </div>
  
  <!-- Concealment Strategy Breakdown -->
  <div class="row">
    <h3><u>Caption Generation Pipeline</u></h3> <br>
    <p class="absfont text-justify">
      The caption generation process leverages prior knowledge of threat-specific metadata and synonym sets to dynamically construct captions 
      for each baggage scan collected using the STING Protocol. The matadata includes the baggage type, threat category, threat location and pose
       (e.g., corner flat), followed by levels of concealment and clutter, and additional normal items.
    </p><br></br>

    <!-- Full-Width Image with Lightbox -->
    <div class="text-center">
      <a href="javascript:void(0);" onclick="openModal('captionModal', 'captionModalImg', this)">
          <img class="img-fluid img-responsive" src="./images/CaptionGen2.png" style="max-width: 100%;" alt="STING Caption Generation">
      </a>
  </div>
  
  <!-- Modal for Caption Generation Image -->
  <div id="captionModal" class="modal">
      <span class="close" onclick="closeModal('captionModal')">&times;</span>
      <img class="modal-content" id="captionModalImg">
  </div> 
      </div>

  <br><br>
  <hr style="border: 0; height: 1px; background: #d3d3d3; margin: 30px 0;">    

</div>
    
  <div class="container" id = "stingbee">
      <h1>üìå STING-BEE: Training and Evaluation Pipeline</h1> <br> 
      <div class="text-center">
        <a href="javascript:void(0);" onclick="openModal('stingBeeModal', 'stingBeeModalImg', this)">
          <img class="img-fluid" src="./images/STCray_Proposed_CVPR_V4.png" style="max-width: 99%;" alt="STING-BEE Training and Evaluation Pipeline">
        </a>
      </div>
      
      <!-- Modal for STCray_Proposed_CVPR_V4 -->
      <div id="stingBeeModal" class="modal">
        <span class="close" onclick="closeModal('stingBeeModal')">&times;</span>
        <img class="modal-content" id="stingBeeModalImg">
      </div> <br><br> 
      <p class="absfont">
We train <b>STING-BEE</b> in a multi-stage process to build domain expertise and grounding capabilities. For training STING-BEE for X-ray security screening, we created an instruction-following 
dataset by creating question-answer pairs for scans in our STCray dataset. These question-answer pairs follow structured templates specific to the language-based vision tasks. 
STING-BEE introduces <b>specialized task-identification tokens</b> to differentiate between diverse vision-language tasks demanding different levels of spatial awareness.
</p>
  </div> <br> 
  <hr style="border: 0; height: 1px; background: #d3d3d3; margin: 30px 0;">  

     <div class="container" id="result">
        <h1>üìå Results</h1> <br> 
        <p class="absfont">
            Qualitative examples below showcasing the capabilities of <b>STING-BEE</b> across multiple vision-language tasks, including Scene Comprehension, Referring Threat Localization, Visual Grounding, and Visual Question Answering (VQA). 
            The examples span **four X-ray security datasets**‚Äî <b>STCray, SIXray, PIDray, and Compass XP</b>, demonstrating STING-BEE‚Äôs cross-domain generalization despite scanner variations.
        </p>
        <br><br>
        <p class="absfont text-justify">Qualitative examples showcasing the capabilities of STING-BEE across diverse vision-language tasks: 
          Scene Comprehension (d, e, f, i), Referring Threat Localization (a, j), Visual Grounding (c, g), and Visual Question Answering (b, h). 
          These examples span four X-ray security datasets‚Äî STCray, SIXray, PIDray, and Compass XP ‚Äî illustrating STING-BEE‚Äôs robustness and adaptability to diverse X-ray imagery.</p>
        <!-- Figure 1: STING-BEE's Vision-Language Tasks -->
        <div class="text-center">
            <a href="javascript:void(0);" onclick="openModal('fig23Modal', 'fig23Img', this)">
                <img class="img-fluid" src="./images/Qual2_V2.png" style="max-width: 75%;" alt="STING-BEE Vision-Language Tasks">
            </a>
            
        </div><br><br>
    
        <!-- Modal for Figure 23 -->
        <div id="fig23Modal" class="modal">
            <span class="close" onclick="closeModal('fig23Modal')">&times;</span>
            <img class="modal-content" id="fig23Img">
        </div>
        <br><br>
    
        <!-- Figure 2: Threat Classification Across Different Scenarios -->
        <div class="row">
          <h3><u>Scene Comprehension</u></h3> <br>
          <p class="absfont text-justify">The images display diverse objects such as guns, pliers, wrenches, power banks, scissors, and 
            hammers across different scenarios, highlighting the robustness of STING-BEE in understanding and categorizing threat items within X-ray imagery.</p>
            <div class="text-center">
            <a href="javascript:void(0);" onclick="openModal('fig24Modal', 'fig24Img', this)">
                <img class="img-fluid" src="./images/Qual3_V2.png" style="max-width: 75%;" alt="STING-BEE Scene Comprehension">
            </a>
          </div>
            
        </div>
    
        <!-- Modal for Figure 24 -->
        <div id="fig24Modal" class="modal">
            <span class="close" onclick="closeModal('fig24Modal')">&times;</span>
            <img class="modal-content" id="fig24Img">
        </div>
        <br><br>
    
        <!-- Figure 3: Visual Grounding Examples -->
        <div class="row">
          <h3><u>Visual Grounding</u></h3> <br>
          <p class="absfont text-justify">Visual grounding qualitative examples demonstrating STING-BEE‚Äôs ability to 
            describe and localize specific threat items in X-ray baggage scans. The system effectively identifies and highlights objects such as guns, handcuffs, and bullets within diverse scenarios.</p>
          <div class="text-center">
            <a href="javascript:void(0);" onclick="openModal('fig25Modal', 'fig25Img', this)">
                <img class="img-fluid" src="./images/Qual4_V2.png" style="max-width: 75%;" alt="STING-BEE Visual Grounding">
            </a>
           </div> 
        </div>
    
        <!-- Modal for Figure 25 -->
        <div id="fig25Modal" class="modal">
            <span class="close" onclick="closeModal('fig25Modal')">&times;</span>
            <img class="modal-content" id="fig25Img">
        </div>
        <br><br>
    
        <!-- Figure 4: Referral Threat Localization -->
        <div class="row">
          <h3><u>Referral Threat Localization</u></h3> <br>
          <p class="absfont text-justify">Referral threat localization examples showcasing STING-BEE‚Äôs precision in identifying and localizing specific threat items in X-ray baggage scans. 
            The system demonstrates its capability to locate different contraband objects, utilizing bounding box coordinates to highlight their positions within the scans.</p>
        <div class="text-center">
            <a href="javascript:void(0);" onclick="openModal('fig26Modal', 'fig26Img', this)">
                <img class="img-fluid" src="./images/Qual5_V2.png" style="max-width: 85%;" alt="STING-BEE Referral Threat Localization">
            </a>
           </div>
        </div>
    
        <!-- Modal for Figure 26 -->
        <div id="fig26Modal" class="modal">
            <span class="close" onclick="closeModal('fig26Modal')">&times;</span>
            <img class="modal-content" id="fig26Img">
        </div>
        <br><br>
    
        <!-- Figure 5: Visual Question Answering (VQA) -->
        <div class="row">
          <h3><u>Visual Question Answering</u></h3> <br>
          <p class="absfont text-justify">Qualitative examples showcasing the capabilities of STING-BEE in Visual Question Answering (VQA) across diverse question types: 
            (a) Instance Identification, Instance Counting, and Misleading Question resolution, (b) Instance Location and Instance Attribute recognition, and 
            (c) Instance Interaction and Complex Visual Reasoning.</p>
        <div class="text-center">
            <a href="javascript:void(0);" onclick="openModal('fig27Modal', 'fig27Img', this)">
                <img class="img-fluid" src="./images/Qual6_V2.png" style="max-width: 85%;" alt="STING-BEE VQA Examples">
            </a>
          </div>
        </div>
    
        <!-- Modal for Figure 27 -->
        <div id="fig27Modal" class="modal">
            <span class="close" onclick="closeModal('fig27Modal')">&times;</span>
            <img class="modal-content" id="fig27Img">
        </div>
        <br><br>
    </div>
    
      
      <br><br>
      
  <br><br>
  <div class="container" id="cite">
    <h1>Citation</h1> <br> 
    If you use the findings of this research in your work, please cite our paper:
    <br>
    <pre class="div2">@article{velayudhan2025stingbee,
      title={STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection},
      author={Divya Velayudhan, Abdelfatah Ahmed, Mohamad Alansari, Neha Gour, Abderaouf Behouch, Taimur Hassan, Syed Talal Wasim, Nabil Maalej, Muzammal Naseer, Juergen Gall, Mohammed Bennamoun, Ernesto Damiani, Naoufel Werghi}, 
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2025}<!-- journal={arXiv preprint arXiv:2504.02823}, --> 
    }</pre>
  </div>
  <br><br>
  <div class="container" id="contact">
    <h1>Contact</h1>
    <br>
    <p class="absfont">
      For any inquiries regarding STING-BEE, please feel free to contact
      <strong>Divya Velayudhan</strong> at 
      <a href="mailto:divya.velayudhan@ku.ac.ae" style="color: #007bff; text-decoration: underline; font-weight: bold;">
        divya.velayudhan@ku.ac.ae
      </a>
    </p>
    <br>
  </div>
  

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  
  
    <style>
      /* Styling for the Lightbox Modal */
.modal {
    display: none;
    position: fixed;
    z-index: 9999;
    top: 0;
    left: 0;
    width: 100%;
    height: 118%;
    background-color: rgba(0, 0, 0, 0.8);
    display: flex; /* Enable Flexbox */
    justify-content: center; /* Center horizontally */
    align-items: center; /* Center vertically */
    padding: 60px 200px; /* Add some padding to prevent the image from touching the edges */
}

/* Center the image properly */
.modal-content {
    max-width: 90vw; /* Ensures the image never exceeds the viewport width */
    max-height: 90vh; /* Ensures the image never exceeds the viewport height */
    object-fit: contain; /* Keeps the aspect ratio */
    border-radius: 8px;
    box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.5); /* Optional: Add a shadow for better visibility */
    transition: transform 0.2s ease-in-out; /* Smooth zoom effect */
}

/* Close button styling */
.close {
    position: absolute;
    top: 15px;
    right: 25px;
    color: white;
    font-size: 35px;
    font-weight: bold;
    cursor: pointer;
}
.close:hover {
    color: #ff7675; /* Light red on hover */
}
    </style>
    
    <script>
      // Ensure all modals are hidden on page load
      document.addEventListener("DOMContentLoaded", function () {
        document.querySelectorAll(".modal").forEach(function (modal) {
          modal.style.display = "none";
        });
      });
    
      function openModal(modalId, imgId, element) {
        var modal = document.getElementById(modalId);
        var modalImg = document.getElementById(imgId);
    
        // Show modal first to prevent repositioning after load
        modal.style.display = "block";
    
        // Temporarily hide image before setting source
        modalImg.style.visibility = "hidden";
    
        // Set the image source
        modalImg.src = element.querySelector("img").src;
    
        // Wait for the image to load, then make it visible
        modalImg.onload = function () {
          modalImg.style.visibility = "visible";
        };
      }
    
      function closeModal(modalId) {
        document.getElementById(modalId).style.display = "none";
      }
    
      // Close modal when clicking outside the image
      document.addEventListener("click", function (event) {
        document.querySelectorAll(".modal").forEach(function (modal) {
          if (event.target === modal) {
            modal.style.display = "none";
          }
        });
      });
    </script>

  </body>
</html>
